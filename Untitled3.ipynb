{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10dfaef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import imghdr\n",
    "import numpy as np\n",
    "import pathlib\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Dropout, Flatten, Dense, Reshape, LSTM, BatchNormalization\n",
    "from tensorflow.keras.optimizers import SGD, RMSprop, Adam\n",
    "from keras import backend as K\n",
    "from keras.constraints import maxnorm\n",
    "import tensorflow as tf\n",
    "from scipy import io as spio\n",
    "import idx2numpy  # sudo pip3 install idx2numpy\n",
    "from matplotlib import pyplot as plt\n",
    "from typing import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "270d885f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.transform\n",
    "\n",
    "root_directory = 'Cyrillic'\n",
    "files = os.listdir(root_directory)\n",
    "\n",
    "def make_background(image):\n",
    "    file_without_extension = image.split('.')[0]\n",
    "    image = cv2.imread(image, cv2.IMREAD_UNCHANGED)\n",
    "    trans_mask = image[:, :, 3] == 0\n",
    "    image[trans_mask] = [255, 255, 255, 255]\n",
    "    new_img = cv2.cvtColor(image, cv2.COLOR_BGRA2BGR)\n",
    "    print(image)\n",
    "    print(file_without_extension)\n",
    "    cv2.imwrite(file_without_extension + '.png', new_img)\n",
    "\n",
    "def shift(image):\n",
    "    img = cv2.imread(image)\n",
    "    file_without_extension = image.split('.')[0]\n",
    "    arr_translation = [[15, -15], [-15, 15], [-15, -15],\n",
    "                               [15, 15]]\n",
    "    arr_caption=['15-15','-1515','-15-15','1515']\n",
    "    for i in range(4):\n",
    "        transform = skimage.transform.AffineTransform(\n",
    "                translation=tuple(arr_translation[i]))\n",
    "        warp_image = skimage.transform.warp(img, transform, mode=\"wrap\")\n",
    "        img_convert = cv2.convertScaleAbs(warp_image,\n",
    "                                                  alpha=(255.0))\n",
    "        print(file_without_extension +\n",
    "                arr_caption[i] + '.png')\n",
    "        s = cv2.imwrite(file_without_extension +\n",
    "                arr_caption[i] + '.png', img_convert)\n",
    "        print(s)\n",
    "        \n",
    "for i in range(len(files)):\n",
    "    images = os.listdir(root_directory + \"\\\\\" + files[i])\n",
    "    for j in range(len(images)):\n",
    "        shift(root_directory + \"\\\\\" + files[i] + \"\\\\\" + images[j])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "8a7d203f",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_directory = 'Cyrillic'\n",
    "files = os.listdir(root_directory)\n",
    "\n",
    "def balancing():\n",
    "    arr_len_files = []\n",
    "    \n",
    "    for i in range(len(files)):\n",
    "        images = os.listdir(root_directory + \"\\\\\" + files[i])\n",
    "        path = root_directory + \"\\\\\" + files[i]\n",
    "        arr_len_files.append(len(images))\n",
    "        \n",
    "    min_value=min(arr_len_files)\n",
    "    for i in range(len(files)):\n",
    "        vall = root_directory + \"\\\\\" + files[i]\n",
    "        folder = os.listdir(vall)\n",
    "        arr = []\n",
    "        for i_file in folder:\n",
    "            arr.append(vall + \"\\\\\" + i_file)\n",
    "        d = 0\n",
    "        k = len(arr)\n",
    "        for i in arr:\n",
    "            os.remove(i)\n",
    "            d += 1\n",
    "            if d == k - min_value:\n",
    "                break\n",
    "    \n",
    "balancing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "bcbd6ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting split-folders\n",
      "  Downloading split_folders-0.4.3-py3-none-any.whl (7.4 kB)\n",
      "Installing collected packages: split-folders\n",
      "Successfully installed split-folders-0.4.3\n"
     ]
    }
   ],
   "source": [
    "!pip install split-folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c1fa733c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 55040 files [01:14, 740.57 files/s]\n"
     ]
    }
   ],
   "source": [
    "import splitfolders\n",
    "\n",
    "input_folder = \"Cyrillic\"\n",
    " \n",
    "splitfolders.ratio(input_folder, 'CyrillicSplit', ratio = (0.65, 0.2, 0.15), seed=13, group_prefix=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "fd04c34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 35776 images belonging to 32 classes.\n",
      "Found 8256 images belonging to 32 classes.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 276, 276, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 138, 138, 16)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 136, 136, 32)      4640      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 68, 68, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 66, 66, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 33, 33, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 69696)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               35684864  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                16416     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 35,724,864\n",
      "Trainable params: 35,724,864\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-115-1caa9b3de04d>:31: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(train_generator,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "895/895 [==============================] - 929s 1s/step - loss: 0.9568 - accuracy: 0.7372 - val_loss: 0.3913 - val_accuracy: 0.8860\n",
      "Epoch 2/2\n",
      "895/895 [==============================] - 923s 1s/step - loss: 0.1644 - accuracy: 0.9489 - val_loss: 0.3779 - val_accuracy: 0.8951\n"
     ]
    }
   ],
   "source": [
    "ImageDataGenerator = tf.keras.preprocessing.image.ImageDataGenerator\n",
    "TRAINING_DIR = \"C:\\\\Users\\\\DNS\\\\Desktop\\\\Creating the simplest neural network\\\\CyrillicSplit\\\\train\"\n",
    "train_datagen = ImageDataGenerator(rescale=1.0 / 255.)\n",
    "train_generator = train_datagen.flow_from_directory(TRAINING_DIR,\n",
    "                              batch_size=40,\n",
    "                              class_mode='binary',\n",
    "                              target_size=(278,278))\n",
    "\n",
    "VALIDATION_DIR = \"C:\\\\Users\\\\DNS\\\\Desktop\\\\Creating the simplest neural network\\\\CyrillicSplit\\\\test\"\n",
    "validation_datagen = ImageDataGenerator(rescale=1.0 / 255.)\n",
    "validation_generator = validation_datagen.flow_from_directory(VALIDATION_DIR,\n",
    "                                      batch_size=40,\n",
    "                                      class_mode='binary',\n",
    "                                      target_size=(278,278))\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(16, (3, 3), activation='relu', \n",
    "                           input_shape=(278,278, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam', \n",
    "loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "history = model.fit_generator(train_generator,\n",
    "                           epochs=2,\n",
    "                           verbose=1,\n",
    "                           validation_data=validation_generator)\n",
    "\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "abd1b663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ш\n"
     ]
    }
   ],
   "source": [
    "def print_letter(result):\n",
    "    letters = \"АБВГДЕЖЗИЙКЛМНОПРСТУФХЦЧШЩЪЫЬЭЮЯ\"\n",
    "    return letters[result]\n",
    "\n",
    "def predicting(path_to_image):\n",
    "    image = keras.preprocessing.image\n",
    "    model = keras.models.load_model(os.getcwd() + \"\\\\\" + \"model.h5\")\n",
    "\n",
    "    img = image.load_img(path_to_image, target_size=(278, 278))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    images = np.vstack([x])\n",
    "    classes = model.predict(images, batch_size=1)\n",
    "    result = int(np.argmax(classes))\n",
    "    result = print_letter(result)\n",
    "    print(result)\n",
    "    \n",
    "predicting(r'C:\\Users\\DNS\\Desktop\\Creating the simplest neural network\\CyrillicSplit\\test\\Ш\\58befcdfefbcc-1515.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab8a2a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
